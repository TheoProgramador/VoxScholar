# ğŸ™ï¸ Real-Time Speech Pipeline (Faster-Whisper + Groq)

## ğŸ“Œ Problema

SoluÃ§Ãµes de transcriÃ§Ã£o em tempo real geralmente exigem:
- infraestrutura pesada
- dependÃªncia total de APIs externas
- latÃªncia alta
- custo recorrente

Este projeto resolve isso com uma abordagem hÃ­brida:

- ğŸ”¹ TranscriÃ§Ã£o local usando Faster-Whisper (baixo custo, alta eficiÃªncia)
- ğŸ”¹ Processamento opcional via Groq API para respostas rÃ¡pidas com LLM
- ğŸ”¹ Arquitetura leve e minimalista

O foco Ã© performance e controle.

---

## ğŸ§  Arquitetura

Microfone â†’ Faster-Whisper (local) â†’ Processamento opcional via Groq â†’ Resposta

Pode rodar:
- 100% local
- Local + Groq
- CPU ou GPU

---

## ğŸ–¥ï¸ Requisitos de Hardware

### Modo mÃ­nimo (CPU)
- Python 3.10+
- 4GB RAM
- Funciona atÃ© em mÃ¡quinas modestas

### Modo recomendado (GPU)
- CUDA compatÃ­vel
- 6GB+ VRAM para modelos maiores

Faster-Whisper Ã© altamente otimizado e pode rodar atÃ© em dispositivos modestos.

---

## ğŸ”‘ ConfiguraÃ§Ã£o da API Groq (Opcional)

Se quiser usar processamento via Groq:

1. Crie uma conta em: https://console.groq.com
2. Gere sua API Key
3. Configure como variÃ¡vel de ambiente

### Windows (PowerShell)

```powershell
setx GROQ_API_KEY "sua_chave_aqui"

python main.py